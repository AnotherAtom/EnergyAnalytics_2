{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 2 - Forecasting Electricity Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from IPython.display import Markdown as md\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import pmdarima as pm\n",
    "from pmdarima import pipeline, arima, model_selection\n",
    "from math import sqrt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in required data, and filtering according to requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_P = os.path.join(os.getcwd(),'data/Elspotprices2.csv')\n",
    "df_prices = pd.read_csv(file_P)\n",
    "df_prices[\"HourUTC\"] = pd.to_datetime(df_prices[\"HourUTC\"])\n",
    "df_prices = df_prices.loc[(df_prices['PriceArea']==\"DK2\")][[\"HourUTC\",\"SpotPriceDKK\"]]\n",
    "df_prices = df_prices.loc[df_prices[\"HourUTC\"].dt.year.isin([2019,2020,2021,2022,2023])]\n",
    "df_prices = df_prices.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Develop an ARIMA model to predict electricity prices. Your goal in all following tasks is to achieve the best possible performance. In both sub-tasks report the RMSE values you achieve with your models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 \n",
    "Use NO exogenous variables in your model and make day-ahead prediction for your testing dataset. You can use a seasonal ARIMA or FourierFeaturizer and any data transformation you want in your model, but no exogenous features from df data. Establish a suitable persistence forecast and report the RMSE values in both cases (your model and  persistence). Briefly discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by dividing the data into training- and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the time intervial.\n",
    "t_s_data = pd.Timestamp(dt.datetime(2019, 1, 1, 0, 0, 0))\n",
    "t_e_data = pd.Timestamp(dt.datetime(2023, 8, 31, 23, 0, 0))\n",
    "\n",
    "data_all = df_prices.loc[(df_prices['HourUTC'] >= t_s_data) & (df_prices['HourUTC'] <= t_e_data)]\n",
    "data_all = data_all.reset_index(drop=True)\n",
    "\n",
    "# We use the time intervial.\n",
    "t_s_train = pd.Timestamp(dt.datetime(2023, 1, 1, 0, 0, 0))\n",
    "t_e_train = pd.Timestamp(dt.datetime(2023, 11, 30, 23, 0, 0))\n",
    "\n",
    "train = df_prices.loc[(df_prices['HourUTC'] >= t_s_train) & (df_prices['HourUTC'] <= t_e_train)]\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "t_s_test = pd.Timestamp(dt.datetime(2023, 12, 1, 0, 0, 0))\n",
    "t_e_test= pd.Timestamp(dt.datetime(2023, 12, 31, 23, 0, 0))\n",
    "\n",
    "test = df_prices.loc[(df_prices['HourUTC'] >= t_s_test) & (df_prices['HourUTC'] <= t_e_test)]\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the two sets besides each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 4), dpi=100)\n",
    "\n",
    "plt.plot(train['HourUTC'], train['SpotPriceDKK'])\n",
    "plt.plot(test['HourUTC'], test['SpotPriceDKK'])\n",
    "plt.plot(data_all['HourUTC'], data_all['SpotPriceDKK'], alpha=0.25)\n",
    "\n",
    "\n",
    "plt.title('SpotPricesDKK')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Price [DKK/MWh]')\n",
    "\n",
    "plt.legend([\"Training set\", \"Testing set\" , \"All data\"])\n",
    "plt.tight_layout()\n",
    "plt.grid(alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a method that automatically fits the best model for us. We will first remove all the columns other than the numericals values for SpotPricesDKK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Arima = train['SpotPriceDKK']\n",
    "test_Arima = test['SpotPriceDKK']\n",
    "\n",
    "# Automatically fit the ARIMA model\n",
    "model = pm.auto_arima(train_Arima, seasonal = True, trace = True, maxiter = 5, stepwise = True, method = 'nm', m = 24)\n",
    "#model = pm.arima.ARIMA(order=(1,1,5), seasonal_order=(2,0,2,24)) #(2,0,2)\n",
    "#model.fit(train_Arima)\n",
    "\n",
    "# Here the optimal model was found through auto_arima(), but later fit manually to save time during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day-ahead prediction\n",
    "pred = []\n",
    "\n",
    "for i in range(0, len(test_Arima), 24):\n",
    "    # Predict next 24 values for all time series at once\n",
    "    pred_temp = model.predict(24)\n",
    "    pred.extend(pred_temp)\n",
    "    \n",
    "    # Update model with actual values for the next 24 time steps in one go\n",
    "    model.update(test_Arima[i:i+24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, a simple persistence model is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers = np.zeros(len(test_Arima)).tolist()\n",
    "\n",
    "for i in range(24, len(test_Arima), 24):\n",
    "    for j in range(24):\n",
    "        pers[i+j] = test_Arima[(i-24)+j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data is plotted along with the ARIMA predictions and the persistence model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(test['HourUTC'], test_Arima, label='Data')\n",
    "plt.plot(test['HourUTC'], pers, label='Persistence', linestyle=\"dotted\")\n",
    "plt.plot(test['HourUTC'], pred, label='Prediction', linestyle=\"dashed\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error metrics for both are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error metrics\n",
    "RMSE_AR_pred = sqrt(mean_squared_error(test_Arima, pred))\n",
    "MAE_AR_pred = mean_absolute_error(test_Arima, pred)\n",
    "print('Prediction')\n",
    "print('\\t Root-mean-square error: ', round(RMSE_AR_pred,2))\n",
    "print('\\t Mean absolute error: ', round(MAE_AR_pred,2))\n",
    "\n",
    "print('')\n",
    "\n",
    "RMSE_AR_pers = sqrt(mean_squared_error(test_Arima, pers))\n",
    "MAE_AR_pers = mean_absolute_error(test_Arima, pers)\n",
    "print('Persistence')\n",
    "print('\\t Root-mean-square error: ', round(RMSE_AR_pers,2))\n",
    "print('\\t Mean absolute error: ', round(MAE_AR_pers,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the day-ahead prediction with no exogenous variables is only slightly better than simply assuming the same values as the previous day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "Add any exogenous variables you want (maximum 3) and repeat the process (choose/optimize\n",
    "your model and evaluate it for the day-ahead prediction). What exogenous variables helped you improve the prediction and how did you choose the specific ones? Report the RMSE value and compare your results with those from task 1.1 and briefly discuss them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the data with exogenous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_P = os.path.join(os.getcwd(),'data/ProdConData.csv')\n",
    "df_data = pd.read_csv(file_P)\n",
    "df_data[\"HourUTC\"] = pd.to_datetime(df_data[\"HourUTC\"])\n",
    "df_data = df_data.loc[df_data[\"HourUTC\"].dt.year.isin([2019,2020,2021,2022,2023])]\n",
    "df_data = df_data.loc[df_data[\"PriceArea\"].isin([\"DK2\"])]\n",
    "df_data = df_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which variables do we have to choose from?\n",
    "for col in df_data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(5,8):\n",
    "    train.insert(i, df_data.columns[i+1], df_data[df_data.columns[i+1]])\n",
    "\n",
    "'''\n",
    "\n",
    "train.insert(2, 'ExchangeSE_MWh', df_data['ExchangeSE_MWh'])\n",
    "train.insert(3, 'GrossConsumptionMWh', df_data['GrossConsumptionMWh'])\n",
    "# train.insert(4, 'OffshoreWindGe100MW_MWh', df_data['OffshoreWindGe100MW_MWh'])\n",
    "\n",
    "train = train.drop(columns=['HourUTC', 'SpotPriceDKK'])\n",
    "train = train.dropna(axis=1)\n",
    "\n",
    "for col in train.columns:\n",
    "    print('Exogenous variables chosen: \\n', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exog = pd.DataFrame(train[['Exchange_SE', 'GrossConsumptionMWh', 'Offshore_Gen']])\n",
    "\n",
    "X_train_ar = np.column_stack([np.arange(1, len(train_Arima)+1), train_Arima])\n",
    "\n",
    "model.fit(train_Arima, X = X_train_ar)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KØR DETTE NEDENFOR, JEG TROR train[] og X_f[] HAR DE RIGTIGE FORMATER (LÆS OPGAVEBESKRIVELSEN), SÅ JEG TROR PREDICT() VIL VIRKE NU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day-ahead prediction\n",
    "pred_exog = []\n",
    "X_f = train[:24]\n",
    "\n",
    "for i in range(0, len(test_Arima), 24):\n",
    "    # Predict next 24 values for all time series at once\n",
    "    pred_temp = model.predict(24, X_f)\n",
    "    pred_exog.extend(pred_temp)\n",
    "    \n",
    "    # Update model with actual values for the next 24 time steps in one go\n",
    "    model.update(test_Arima[i:i+24], X_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(test['HourUTC'], test_Arima, label='Data')\n",
    "plt.plot(test['HourUTC'], pred_exog, label='Prediction with Exogenous', linestyle=\"dashed\", color=\"red\")\n",
    "plt.plot(test['HourUTC'], pred, label='Prediction', linestyle=\"dotted\", color=\"green\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error metrics\n",
    "RMSE_AR_pred = sqrt(mean_squared_error(test_Arima, pred_exog))\n",
    "MAE_AR_pred = mean_absolute_error(test_Arima, pred_exog)\n",
    "print('Prediction')\n",
    "print('\\t Root-mean-square error: ', round(RMSE_AR_pred,2))\n",
    "print('\\t Mean absolute error: ', round(MAE_AR_pred,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAVER MODEL MED SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the SARIMAX model\n",
    "model = SARIMAX(train_Arima, exog=pred_exog, order=(1,1,5), seasonal_order=(2,0,2,24))\n",
    "#model_fit = model.fit(disp=False)  # 'disp=False' to turn off diagnostic output\n",
    "\n",
    "# Display the summary of the model\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.insert(2, \"Exchange_SE\", df_data[\"ExchangeSE_MWh\"])\n",
    "test.insert(3, \"GrossConsumptionMWh\", df_data[\"GrossConsumptionMWh\"])\n",
    "test.insert(4, \"Offshore_Gen\", df_data[\"OffshoreWindGe100MW_MWh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Arima = test['SpotPriceDKK']  # Replace 'SpotPriceDKK' with your dependent variable\n",
    "exog_test = test[['Exchange_SE', 'GrossConsumptionMWh', 'Offshore_Gen']]\n",
    "\n",
    "# Forecast using the SARIMAX model\n",
    "#forecasts = model_fit.predict(start=len(train), end=len(train) + len(test) - 1, exog=exog_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rmse = np.sqrt(mean_squared_error(test_Arima, forecasts))\n",
    "print(\"RMSE for model with exogenous variables:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fourier = pm.preprocessing.FourierFeaturizer(m=24, k = 12)\n",
    "\n",
    "#model_fourier_fit = model_fourier.fit(train, X = exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(train[\"SpotPriceDKK\"], train_size=2184)\n",
    "\n",
    "train, test = model_selection.train_test_split(train[\"SpotPriceDKK\"], train_size=2184)\n",
    "X_train, X_test = model_selection.train_test_split(train[[\"OffshoreWindGe100MW_MWh\",\"ExchangeSE_MWh\",\"GridLossDistributionMWh\"]], train_size=2184)\n",
    "\n",
    "X_train_ar = np.column_stack([np.arange(1, n+1), X_train])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
