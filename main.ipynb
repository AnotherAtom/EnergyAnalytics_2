{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 2 - Forecasting Electricity Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will load all of the different packages needed to run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary data analysis packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, Great! Now that its done, lets load in our data from our datafile. The datafile is found in the folder with Data and will be acceced through the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_P = os.path.join(os.getcwd(),'data/Elspotprices2.csv')\n",
    "df_prices = pd.read_csv(file_P)\n",
    "df_prices[\"HourUTC\"] = pd.to_datetime(df_prices[\"HourUTC\"])\n",
    "df_prices = df_prices.loc[(df_prices['PriceArea']==\"DK2\")][[\"HourUTC\",\"SpotPriceDKK\"]]\n",
    "df_prices = df_prices.loc[df_prices[\"HourUTC\"].dt.year.isin([2019,2020,2021,2022,2023])]\n",
    "df_prices = df_prices.reset_index(drop=True)\n",
    "file_P = os.path.join(os.getcwd(),'data/ProdConData.csv')\n",
    "df_data = pd.read_csv(file_P)\n",
    "df_data[\"HourUTC\"] = pd.to_datetime(df_data[\"HourUTC\"])\n",
    "df_data = df_data.loc[df_data[\"HourUTC\"].dt.year.isin([2019,2020,2021,2022,2023])]\n",
    "df_data = df_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets get to the fun part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I will list all the different tasks for this project to highlight what should be done (and what shouldnt?!...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Develop an ARIMA model to predict electricity prices. Your goal in all following tasks is to achieve the best possible performance. In both sub-tasks report the RMSE values you achieve with your models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 \n",
    "Use NO exogenous variables in your model and make day-ahead prediction for your testing dataset. You can use a seasonal ARIMA or FourierFeaturizer and any data transformation you want in your model, but no exogenous features from df data. Establish a suitable persistence forecast and report the RMSE values in both cases (your model and  persistence). Briefly discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "Add any exogenous variables you want (maximum 3) and repeat the process (choose/optimize\n",
    "your model and evaluate it for the day-ahead prediction). What exogenous variables helped you improve the prediction and how did you choose the specific ones? Report the RMSE value and compare your results with those from task 1.1 and briefly discuss them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 \n",
    "\n",
    "Her er Mads Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of data manipulation / visualization libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import of data visualization libraries\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import of data preprocessing libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Import of tensorflow libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Bidirectional, Dropout, Activation, Dense, LSTM\n",
    "# from tensorflow.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the spot prices\n",
    "file_Path = os.path.join(os.getcwd(),'Elspotprices2.csv')\n",
    "df_prices = pd.read_csv(file_Path)\n",
    "\n",
    "# We convert the HourUTC column to datetime and set the column only at the DK2 price area\n",
    "df_prices[\"HourUTC\"] = pd.to_datetime(df_prices[\"HourUTC\"])\n",
    "df_prices = df_prices.loc[(df_prices['PriceArea']==\"DK2\")][[\"HourUTC\",\"SpotPriceDKK\"]]\n",
    "df_prices = df_prices.loc[df_prices[\"HourUTC\"].dt.year.isin([2019,2020,2021,2022,2023])]\n",
    "df_prices = df_prices.reset_index(drop=True)\n",
    "\n",
    "# We load the production and consumption data\n",
    "file_Path = os.path.join(os.getcwd(),'ProdConData.csv')\n",
    "df_data = pd.read_csv(file_Path)\n",
    "\n",
    "# \"e convert the HourUTC column to datetime\n",
    "df_data[\"HourUTC\"] = pd.to_datetime(df_data[\"HourUTC\"])\n",
    "df_data = df_data.loc[df_data[\"HourUTC\"].dt.year.isin([2019,2020,2021,2022,2023])]\n",
    "df_data = df_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a training data set from our data. Here we will be using the data for the DK2 spot price from 1/1-2019 - 30/11-2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set up the starting date and the ending date for the training data\n",
    "start_date = pd.to_datetime('2019-01-01 00:00:00')\n",
    "end_date = pd.to_datetime('2023-11-30 23:00:00')\n",
    "training_df_prices = df_prices[(df_prices['HourUTC'] >= start_date) & (df_prices['HourUTC'] <= end_date)]\n",
    "\n",
    "# We create the new dataframe for the training data\n",
    "training_data = pd.DataFrame({'DateTime': training_df_prices['HourUTC'], 'DK2Prices': training_df_prices['SpotPriceDKK']})\n",
    "\n",
    "# We can plot the training data\n",
    "training_data.plot(x='DateTime', y='DK2Prices', kind='line')\n",
    "plt.xlabel('DateTime')\n",
    "plt.ylabel('DK2Prices')\n",
    "plt.title('Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# We create the scaled values of the spotprices\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mMinMaxScaler\u001b[49m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# fit the format of the scaler -> convert shape from (1000, ) -> (1000, 1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m SpotPriceDKK \u001b[38;5;241m=\u001b[39m training_df_prices\u001b[38;5;241m.\u001b[39mSpotPriceDKK\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# We create the scaled values of the spotprices\n",
    "scaler = MinMaxScaler()\n",
    "# fit the format of the scaler -> convert shape from (1000, ) -> (1000, 1)\n",
    "SpotPriceDKK = training_df_prices.SpotPriceDKK.values.reshape(-1, 1)\n",
    "scaled_SpotPriceDKK = scaler.fit_transform(SpotPriceDKK)\n",
    "\n",
    "seq_len = 25\n",
    "\n",
    "# We we can define the function for splitting the data into sequences\n",
    "def split_into_sequences(data, seq_len):\n",
    "    n_seq = len(data) - seq_len + 1\n",
    "    return np.array([data[i:(i+seq_len)] for i in range(n_seq)])\n",
    "\n",
    "# And for splitting the data into training and test sets\n",
    "def get_train_test_sets(data, seq_len, train_frac):\n",
    "    sequences = split_into_sequences(data, seq_len)\n",
    "    n_train = int(sequences.shape[0] * train_frac)\n",
    "    x_train = sequences[:n_train, :-1, :]\n",
    "    y_train = sequences[:n_train, -1, :]\n",
    "    x_test = sequences[n_train:, :-1, :]\n",
    "    y_test = sequences[n_train:, -1, :]\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_train_test_sets(scaled_SpotPriceDKK, seq_len, train_frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of the input to drop; helps prevent overfitting\n",
    "dropout = 0.2\n",
    "window_size = seq_len - 1\n",
    "\n",
    "# build a 3-layer LSTM RNN\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(\n",
    "    LSTM(window_size, return_sequences=True, \n",
    "         input_shape=(window_size, x_train.shape[-1]))\n",
    ")\n",
    "\n",
    "model.add(Dropout(rate=dropout))\n",
    "# Bidirectional allows for training of sequence data forwards and backwards\n",
    "model.add(\n",
    "    Bidirectional(LSTM((window_size * 2), return_sequences=True)\n",
    ")) \n",
    "\n",
    "model.add(Dropout(rate=dropout))\n",
    "model.add(\n",
    "    Bidirectional(LSTM(window_size, return_sequences=False))\n",
    ") \n",
    "\n",
    "model.add(Dense(units=1))\n",
    "# linear activation function: activation is proportional to the input\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    validation_split=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the predicted and actual prices\n",
    "predicted_prices = []\n",
    "actual_prices = []\n",
    "\n",
    "# Loop through 30 days\n",
    "for _ in range(30):\n",
    "    # Predict the prices for the next 24 hours\n",
    "    y_pred = model.predict(x_test[:24])\n",
    "    \n",
    "    # Invert the scaler to get the absolute price data\n",
    "    y_test_orig = scaler.inverse_transform(y_test[:24])\n",
    "    y_pred_orig = scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    # Append the predicted and actual prices to the respective lists\n",
    "    predicted_prices.append(y_pred_orig)\n",
    "    actual_prices.append(y_test_orig)\n",
    "    \n",
    "    # Update x_test for the next 24 hours prediction\n",
    "    x_test = np.concatenate([x_test[24:], y_pred.reshape(1, 24, 1)], axis=0)\n",
    "    y_test = np.concatenate([y_test[24:], y_test[:24]], axis=0)\n",
    "\n",
    "# Plot the predicted and actual prices for 30 days\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(30):\n",
    "    plt.plot(np.arange(i*24, (i+1)*24), actual_prices[i], color='orange', linewidth=0.5)\n",
    "    plt.plot(np.arange(i*24, (i+1)*24), predicted_prices[i], color='green', linewidth=0.5)\n",
    "\n",
    "plt.title('SpotPriceDKK Hourly Prices Predicted 24 at a time for 30 days')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Price (DKK/MWh)')\n",
    "plt.legend(['Actual Price', 'Predicted Price'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
