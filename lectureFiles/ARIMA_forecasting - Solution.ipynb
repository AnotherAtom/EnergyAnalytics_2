{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b326b2f9",
   "metadata": {},
   "source": [
    "# Lecture 6 Hands-on F24 - ARIMA forecasting\n",
    "\n",
    "The purpose of this hands-on is to understand how to fit, use and evaluate ARIMA models in Python. Some simple time-series are used as examples because energy-related ones (such as prices or consumption) have more complicated characteristics and require more advanced models. You will work with such time-series in the hands-on of Lecture 7.\n",
    "\n",
    "You will also familiarize yourselves with important operations such as splitting your datasets into training/testing ones, calculating error metrics, visualizing the forecasts etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from IPython.display import Markdown as md\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pmdarima as pm\n",
    "from math import sqrt\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f83063-d1d5-44b8-a496-4f9c2cc84787",
   "metadata": {},
   "source": [
    "## Simulate AR processes and fit AR models\n",
    "\n",
    "- Simulate an AR(2) process and plot the time series\n",
    "- Split the time series into a training and testing dataset\n",
    "- Plot the ACF and PACF plot\n",
    "- You can experiment and create different time series by modifying the AR and MA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275137b-4464-44f7-b7eb-9fd0499552bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AR terms in the simulated process\n",
    "arparams = np.array([0.8, -0.3])\n",
    "ar = np.r_[1, -arparams]\n",
    "\n",
    "# Ignore the MA terms for now and keep them equal to 0\n",
    "maparams = np.array([0])\n",
    "ma = np.r_[1, maparams]\n",
    "\n",
    "# Create the model to generate the samples\n",
    "arma_process = sm.tsa.ArmaProcess(ar, ma)\n",
    "data = arma_process.generate_sample(500)\n",
    "\n",
    "# Split between a training and a testing dataset\n",
    "n = int(0.8*len(data))\n",
    "N = int(len(data))\n",
    "train, test = pm.model_selection.train_test_split(data, train_size=n)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(8, 4), dpi=100)\n",
    "plt.plot(np.arange(1,n+1), train)\n",
    "plt.plot(np.arange(n+1,N+1), test)\n",
    "plt.legend([\"Training set\", \"Testing set\"])\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.grid(alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb8233f",
   "metadata": {},
   "source": [
    "## Plot the ACF/PACF plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbe754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ACF plot\n",
    "pm.plot_acf(train, lags=20, title = \"ACF\", alpha = 0.05);\n",
    "# Check the PACF plot\n",
    "pm.plot_pacf(train, method='ywm', lags=20, title = \"PACF\", alpha = 0.05);\n",
    "\n",
    "# Note that alpha indicates the used confidence in the correlation plots, with 95% (alpha = 0.05) being the standard one.\n",
    "# You can experiment with different values of alpha\n",
    "# Lags controls the number of lagged values in the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff0d79-b481-4b89-9ef7-836844501300",
   "metadata": {},
   "source": [
    "# Fitting models and observing the summary\n",
    "\n",
    "You can now try to fit different models and evaluate which is the better option.\n",
    "- We start by fitting model1 as AR(1) and model2 as AR(2)\n",
    "- You can use: <span style=\"color:blue\">pm.arima.ARIMA(order=(p, d, q))</span> to fit a model of your own choice by setting p, d, q\n",
    "- The summary provides valuable information\n",
    "- You can search for the Ljung-Box (L1) (Q) statistic and why it's different in the two models\n",
    "- You can also search the AIC or BIC statistics. Which model has lower values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c467b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pm.arima.ARIMA(order=(1, 0, 0))\n",
    "model1.fit(train)\n",
    "print(\"Summary of model 1\")\n",
    "print(model1.summary())\n",
    "\n",
    "model2 = pm.arima.ARIMA(order=(2, 0, 0))\n",
    "model2.fit(train)\n",
    "print(\"\\n Summary of model 2\")\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e735e9-4218-49ad-a30a-37e1d134d8f0",
   "metadata": {},
   "source": [
    "## Evaluating the fit of models\n",
    "\n",
    "- We can plot the diagnostics as below\n",
    "- The diagnostics consist of 4 subplots for the normalized residuals of the training dataset:\n",
    "  - The time-series of the residuals -> those should look like white noise\n",
    "  - The histogram should show a normal distribution (closer to thes shown N(0,1))\n",
    "  - The Q-Q plot of the residuals (they should lie as close as possible to the red line)\n",
    "  - The auto-correlation plot of the residuals. No significant correlation should be observed\n",
    " - Which of the two fulfils all criteria?\n",
    " - Does the number of samples play a role? We set N = 500 initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91181aa-224e-4839-8ef4-918bcf7cccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_diagnostics = model1.plot_diagnostics(lags=20, fig=plt.figure())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82252f5-1a71-43a8-9f4c-f1693dd17776",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_diagnostics = model2.plot_diagnostics(lags=20, fig=plt.figure())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b0594",
   "metadata": {},
   "source": [
    "## Predicting with ARIMA models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba6edb",
   "metadata": {},
   "source": [
    "You can use the fitted model to predict future values!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c87a8",
   "metadata": {},
   "source": [
    "### Rolling forecasts\n",
    "Here we are at time step $t$ and forecast the next step $t+1$. Next, we observe the realized true value at $t+1$, and based on this we predict for $t+2$ and so on. In other words, we update our model with new observations and produce new forecasts at each step $t$.\n",
    "\n",
    "Observe the forecast and how it behaves. Discuss it with your colleagues. Experiment with the order of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dcf49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the forecasted values with our model AR(2)\n",
    "frc_values = []\n",
    "\n",
    "# Fit the model\n",
    "model = pm.arima.ARIMA(order=(2, 0, 0))\n",
    "model.fit(train)\n",
    "\n",
    "for k in range(len(test)):\n",
    "    # Predict 1-step ahead\n",
    "    m = model.predict(1)[0]\n",
    "    # Append to the frc_values list\n",
    "    frc_values.append(m)\n",
    "    # Update the model with the last-seen value\n",
    "    model.update(test[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377afb3-9013-4d47-a23a-2e28c604832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "plt.figure(figsize=(8, 4), dpi=100)\n",
    "plt.plot(range(0,len(train)), train)\n",
    "plt.plot(range(len(train)+1,len(data)+1), test)\n",
    "plt.plot(range(len(train)+1,len(data)+1), frc_values)\n",
    "plt.xlim([len(train)-50,len(data)])\n",
    "plt.xlabel(\"t\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.legend([\"Historical data\", \"Real values\", \"Forecasted values\"])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc278336",
   "metadata": {},
   "source": [
    "## Calculate performance metrics\n",
    "\n",
    "- Below we calculate the RMSE and MAE\n",
    "- How else would you assess the performance of the model?\n",
    "- Do you need to check the residuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ffb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_AR = sqrt(mean_squared_error(test, frc_values))\n",
    "MAE_AR = mean_absolute_error(test, frc_values)\n",
    "\n",
    "print(\"The model gives an RMSE of\", float(\"{:.3f}\".format(rmse_AR)))\n",
    "print(\"The model gives an MAE of\", float(\"{:.3f}\".format(MAE_AR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e78ad",
   "metadata": {},
   "source": [
    "## Forecast in one-go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba275a09",
   "metadata": {},
   "source": [
    "Here we produce forecasts for the whole test dataset of in one-go, i.e., without continuously updating the model with new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b221738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pm.arima.ARIMA(order=(2, 0, 0))\n",
    "model.fit(train)\n",
    "frc_values_onego = model.predict(len(test))\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(8, 4), dpi=100)\n",
    "plt.plot(range(0,len(train)), train)\n",
    "plt.plot(range(len(train)+1,len(data)+1), test)\n",
    "plt.plot(range(len(train)+1,len(data)+1), frc_values_onego)\n",
    "plt.xlim([len(train)-50,len(data)])\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.legend([\"Historical data\", \"Real values\", \"Forecasted values\"])\n",
    "\n",
    "# Calculate errors\n",
    "rmse_AR = sqrt(mean_squared_error(test, frc_values_onego))\n",
    "MAE_AR = mean_absolute_error(test, frc_values_onego)\n",
    "print(\"The model gives an RMSE of\", float(\"{:.3f}\".format(rmse_AR)))\n",
    "print(\"The model gives an MAE of\", float(\"{:.3f}\".format(MAE_AR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94886d4a",
   "metadata": {},
   "source": [
    "### Compare the two forecasts. Why do they behave so differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfcad08-410d-4042-9f45-2d1062fe9f82",
   "metadata": {},
   "source": [
    "# ARIMA example\n",
    "\n",
    "Consider the following dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd475abe-5bfb-4688-84f6-046c71d070b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0.643153, 0.565413, 1.02305, -0.295435, -1.63548, 0.906491, 0.151371, 1.58402,\n",
    "        -1.38134, 0.0901513, -0.436639, 0.288482, 0.327499, 0.607486, 1.32946, -0.295326,\n",
    "        1.12644, 1.79775, 2.7662, -1.22518, 0.682238, -0.552159, 2.19328, 2.14682, -1.08043,\n",
    "        2.03189, 0.833014, 1.32183, 0.397554, 3.01139, 3.48769, 2.85506, 1.25216, 1.33211,\n",
    "        2.97688, 0.986708, 2.63425, 1.06554, 1.03385, 2.93462, 2.65984, 0.72205, 0.288134,\n",
    "        1.66116, 2.25676, 1.9578, 4.04734, 4.56202, 3.55477, 3.08978, 3.03434, 2.6849, 1.96305,\n",
    "        3.81255, 2.37639, 3.58423, 3.53872, 3.49335, 3.49195, 3.16102, 4.69291, 4.89491,\n",
    "        3.75537, 3.70994, 2.60701, 3.21296, 2.62482, 3.69524, 2.97964, 3.59984, 4.10841,\n",
    "        3.65618, 3.91009, 4.0143, 3.23322, 2.98325, 2.5568, 3.11426, 2.02182, 4.22683,\n",
    "        3.98335, 3.54927, 5.10158, 5.23455, 5.16627, 4.58551, 4.91136, 4.22619, 4.261, 6.33937,\n",
    "        6.6991, 3.6015, 5.33029, 5.04643, 4.40196, 3.55238, 3.12268, 5.79854, 3.46685, 5.56311]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d45587e-5b60-4d58-9b8f-5d19b41670c0",
   "metadata": {},
   "source": [
    "### Split into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a6e19-7b72-4c5d-9ec6-f4b2cf74c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between a training and a testing dataset\n",
    "n = int(0.8*len(data))\n",
    "N = int(len(data))\n",
    "train, test = pm.model_selection.train_test_split(data, train_size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db675271-7a05-42cd-bee4-dd5fa013028a",
   "metadata": {},
   "source": [
    "### Plot the dataset\n",
    "Is this series stationary by observing it? Plot the differenced time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2d465-afe4-47fc-a33c-a59052400f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4), dpi=100)\n",
    "plt.plot(train[1:], label = \"original\")\n",
    "plt.plot(np.diff(train), label = \"differenced\")\n",
    "plt.tight_layout()\n",
    "plt.legend([\"original\", \"differenced\"])\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.grid(alpha=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f04e69-361e-4b8e-8124-484306e221f2",
   "metadata": {},
   "source": [
    "### Plot the ACF/PACF plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b5bee-77d9-4b61-8a62-df7881777ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ACF plot\n",
    "pm.plot_acf(np.diff(train), lags=10, title = \"ACF\", alpha = 0.05);\n",
    "# Check the PACF plot\n",
    "pm.plot_pacf(np.diff(train), method='ywm', lags=10, title = \"PACF\", alpha = 0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711adba9-5009-4c11-8a0b-2d91f4d053c8",
   "metadata": {},
   "source": [
    "### Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9b675-4871-4791-991e-f9c34156538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = pm.arima.ARIMA(order=(1, 1, 1))\n",
    "model.fit(train)\n",
    "\n",
    "model_diagnostics = model.plot_diagnostics(lags=10, fig=plt.figure())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20dfc7f-328e-461d-b9ef-1796b2633b6f",
   "metadata": {},
   "source": [
    "### Forecast values\n",
    "\n",
    "- Now you can assess your model\n",
    "- Fit a model of your choice and experiment\n",
    "- Check the metrics and plot any diagnostics you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c251c-e743-4f24-81c3-f625eb490654",
   "metadata": {},
   "outputs": [],
   "source": [
    "frc_values = []\n",
    "model = pm.arima.ARIMA(order=(1, 1, 1))\n",
    "model.fit(train)\n",
    "\n",
    "for k in range(len(test)):\n",
    "    m = model.predict(1)[0]\n",
    "    frc_values.append(m)\n",
    "    model.update(test[k])\n",
    "\n",
    "rmse_AR = sqrt(mean_squared_error(test, frc_values))\n",
    "MAE_AR = mean_absolute_error(test, frc_values)\n",
    "\n",
    "print(\"The model gives an RMSE of\", float(\"{:.3f}\".format(rmse_AR)))\n",
    "print(\"The model gives an MAE of\", float(\"{:.3f}\".format(MAE_AR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60106c6-6387-42ce-9513-b81adad39f16",
   "metadata": {},
   "source": [
    "### Using auto-arima\n",
    "\n",
    "- Fortunately, there is a method that can automatically fit the best model for us\n",
    "- You can fit a non-seasonal model as: <span style=\"color:blue\">model = pm.auto_arima(train, trace = True, seasonal = False, stepwise=True, maxiter=10)</span>\n",
    "- Did you choose the same model as the built-in method? Who gets a better performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea2146-2923-47a5-95ed-2fd42d820cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pm.auto_arima(train, trace = True, seasonal = False, stepwise=True, maxiter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f41f06-8cff-4383-a9f1-24fe4cc2dd6f",
   "metadata": {},
   "source": [
    "# Automating the forecasting process\n",
    "\n",
    "- Now you are ready to automate the whole process! Follow the steps below and build a function filling the empty parts\n",
    "- Experiment with the order d and discuss the result in the forecasting\n",
    "- Check the pmdarima documentation on how to use auto arima with a fixed d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704cb38-c6c8-4f1b-968a-a89d5622b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forecaster(data, n, d):\n",
    "    \"\"\"\n",
    "    data: the data to be used in the form of an array\n",
    "    n -> share of training dataset [0,1]\n",
    "    d -> d order of the model, set to None if auto_arima is to optimize its value\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the dataset into training and testing dataset\n",
    "    tr_size = int(n*len(data))\n",
    "    train, test = pm.model_selection.train_test_split(data, train_size = tr_size)\n",
    "                  \n",
    "    # Fit the model\n",
    "    model = pm.auto_arima(train, trace = True, \n",
    "                          seasonal = False, stepwise = True, \n",
    "                          maxiter = 10, d = d)\n",
    "    \n",
    "    # Perform the forecasts\n",
    "    frc_values = []\n",
    "    for k in range(len(test)):\n",
    "        m = model.predict(1)[0]\n",
    "        frc_values.append(m)\n",
    "        model.update(test[k])\n",
    "\n",
    "    # Calculate error metrics\n",
    "    residuals = model.resid()[len(data)-tr_size+1:len(data)]\n",
    "    rmse_AR = sqrt(mean_squared_error(test, frc_values))\n",
    "    MAE_AR = mean_absolute_error(test, frc_values)\n",
    "    print(\"The model gives an RMSE of\", float(\"{:.3f}\".format(rmse_AR)))\n",
    "    print(\"The model gives an MAE of\", float(\"{:.3f}\".format(MAE_AR)))\n",
    "\n",
    "    # Do further analysis\n",
    "    pm.plot_acf(residuals, lags=20, title = \"ACF of residuals\", alpha = 0.05)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(range(0,len(train)), train)\n",
    "    plt.plot(range(len(train)+1,len(data)+1), test)\n",
    "    plt.plot(range(len(train)+1,len(data)+1), frc_values)\n",
    "    plt.xlim([len(train)-40,len(data)])\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"x\")\n",
    "    plt.legend([\"Historical data\", \"Real values\", \"Forecasted values\"])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6066d-ece6-41ff-954b-bcfd8a34d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "Forecaster(data, 0.8, d = None)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
