{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hands-On Lecture 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the data into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "###  Load prosumer data ###\n",
    "file_P = os.path.join(os.getcwd(),'ProsumerHourly_withUTC - Copy.csv')\n",
    "df_pro = pd.read_csv(file_P)\n",
    "df_pro[\"TimeUTC\"] = pd.to_datetime(df_pro[\"TimeUTC\"])\n",
    "df_pro = df_pro.loc[df_pro[\"TimeUTC\"].dt.year.isin([2022,2023])]\n",
    "df_pro = df_pro.reset_index(drop=True)\n",
    "df_pro.rename(columns={'Consumption': 'Load'}, inplace=True)\n",
    "df_pro.rename(columns={'TimeUTC': 'HourUTC'}, inplace=True)\n",
    "df_pro = df_pro[[\"HourUTC\",\"Load\",\"PV\"]]\n",
    "    \n",
    "###  Load weather data ###\n",
    "file_P = os.path.join(os.getcwd(),'WeatherData - Copy.csv')\n",
    "df_weather = pd.read_csv(file_P)\n",
    "df_weather[\"HourUTC\"] = pd.to_datetime(df_weather[\"HourUTC\"])\n",
    "df_weather = df_weather.loc[df_weather[\"HourUTC\"].dt.year.isin([2022,2023])]\n",
    "df_weather = df_weather.drop(df_weather.index[-1])\n",
    "\n",
    "### Merge the dataframes ###\n",
    "df_merged = pd.merge(df_pro, df_weather, on='HourUTC')\n",
    "df_merged = df_merged.drop(['index'], axis=1)\n",
    "\n",
    "df_merged.rename(columns={'snow_soiling_rooftop': 'snow', \n",
    "                          'clearsky_dhi': 'cs_dhi', \n",
    "                          'clearsky_dni': 'cs_dni',\n",
    "                          'clearsky_ghi': 'cs_ghi', \n",
    "                          'clearsky_gti': 'cs_gti',\n",
    "                          'cloud_opacity': 'opacity',\n",
    "                          'dewpoint_temp': 'dew_t'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we plot the data for a time-specific period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3724373603.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    t_s = pd.Timestamp(dt.datetime(, , , , , ))\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Define the period on which you want to build your LSTM model\n",
    "t_s = pd.Timestamp(dt.datetime(, , , , , ))\n",
    "t_e = pd.Timestamp(dt.datetime(, , , , , ))\n",
    "\n",
    "data = df_merged.loc[(df_merged['HourUTC']>=t_s) & (df_merged['HourUTC']<=t_e)]\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=100)\n",
    "plt.plot(data['Load'])\n",
    "plt.title('Consumption')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Consumption (kW)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the consumption 1 hour ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in a training, validation and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = sc.fit_transform(data['Load'].values.reshape(-1,1))\n",
    "look_back =  # Number of previous time steps to use as input features\n",
    "look_ahead = # Number of time steps to look ahead\n",
    "\n",
    "training_rate = \n",
    "split_index = int((len(data)-look_back-look_ahead)*training_rate)\n",
    "validation_rate = \n",
    "split_val_index = int((training_rate+validation_rate)*(len(data)-look_ahead-look_back))\n",
    "testing_rate = \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "# Prepare data for LSTM\n",
    "\n",
    "# Prepare training data\n",
    "X_train, y_train = [], []\n",
    "for i in range(look_back+look_ahead, split_index):\n",
    "    X_train.append(data_scaled[i-look_ahead-look_back:i-look_ahead, 0])\n",
    "    y_train.append(data_scaled[i-look_ahead:i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_val, y_val = [], []\n",
    "# Prepare validation data\n",
    "for i in range(split_index+look_ahead, split_val_index):\n",
    "    X_val.append(data_scaled[i - look_ahead - look_back:i - look_ahead, 0])\n",
    "    y_val.append(data_scaled[i - look_ahead:i, 0])\n",
    "X_val, y_val =  np.array(X_val), np.array(y_val)\n",
    "\n",
    "# Predict on the remaining data\n",
    "X_test, y_test = [], []\n",
    "for i in range(split_val_index+look_ahead, len(data_scaled)+look_ahead):\n",
    "    X_test.append(data_scaled[i-look_ahead-look_back:i-look_ahead, 0])\n",
    "    y_test.append(data_scaled[i-look_ahead:i, 0])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_val = len(X_val)\n",
    "n_test = len(X_test)\n",
    "n_data = len(data)\n",
    "\n",
    "print(f'Size training data: {n_train}, Size validation set: {n_val}, Size testing data: {n_test}, Size data: {n_data}')\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=100)\n",
    "plt.plot(np.arange(look_back+look_ahead,n_train+look_back+look_ahead), y_train)\n",
    "plt.plot(np.arange(n_train+look_ahead+look_back, n_train+n_val+look_back+look_ahead), y_val)\n",
    "plt.plot(np.arange(n_train+n_val+look_ahead+look_back, n_data-look_ahead), y_test)\n",
    "plt.legend([\"Training set\", \"Validation set\", \"Testing set\"])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.ylabel(\"Consumption (kW)\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "# Reshape input data for LSTM [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=, batch_size=, validation_data=(X_val, y_val))\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the predicted consumption vs the actual consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (618,) and (386, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m predicted_consumption \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39minverse_transform(y_pred)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_index\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlook_back\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_consumption\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPredicted Consumption\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad\u001b[39m\u001b[38;5;124m'\u001b[39m][split_index\u001b[38;5;241m-\u001b[39mlook_back:], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Consumption\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\emijo\\AppData\\Local\\anaconda3\\envs\\lstm\\lib\\site-packages\\matplotlib\\pyplot.py:3019\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 3019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3020\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3021\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emijo\\AppData\\Local\\anaconda3\\envs\\lstm\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1605\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1604\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1605\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\emijo\\AppData\\Local\\anaconda3\\envs\\lstm\\lib\\site-packages\\matplotlib\\axes\\_base.py:315\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    314\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emijo\\AppData\\Local\\anaconda3\\envs\\lstm\\lib\\site-packages\\matplotlib\\axes\\_base.py:501\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (618,) and (386, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_consumption = sc.inverse_transform(y_pred)\n",
    "plt.plot(np.arange(n_train+n_val+look_back+look_ahead, n_data-look_ahead), predicted_consumption, label='Predicted Consumption')\n",
    "plt.plot(data['Load'][n_train+n_val+look_ahead+look_back:n_data-look_ahead], label='Actual Consumption')\n",
    "# plt.plot(data['Load'][:n_train+n_val+look_ahead+look_back], label = 'Historical consumption')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Consumption (kW)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your model using the following metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics to evaluate the performance of your model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.models import load_model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R2) Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a new model using dropout and the ReLU activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.activations import relu\n",
    "\n",
    "dropout = \n",
    "\n",
    "# Reshape input data for LSTM [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1), activation=, recurrent_dropout=dropout, dropout=dropout))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=, batch_size=, validation_data=(X_val, y_val))\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics to evaluate the performance of your model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.models import load_model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R2) Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, predict the consumption 12 hours ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = sc.fit_transform(data['Load'].values.reshape(-1,1))\n",
    "split_index = int(len(data)*0.8)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "# Prepare data for LSTM\n",
    "look_back =  # Number of previous time steps to use as input features\n",
    "look_ahead = \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = sc.fit_transform(data['Load'].values.reshape(-1,1))\n",
    "look_back =  # Number of previous time steps to use as input features\n",
    "look_ahead = # Number of time steps to look ahead\n",
    "\n",
    "\n",
    "# Define the ratios for training, validation and testing sets\n",
    "training_rate = \n",
    "validation_rate = \n",
    "testing_rate =\n",
    "\n",
    "\n",
    "split_index = int((len(data)-look_back-look_ahead)*training_rate)\n",
    "split_val_index = int((training_rate+validation_rate)*(len(data)-look_ahead-look_back))\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Prepare data for LSTM\n",
    "# Prepare training data\n",
    "X_train, y_train = [], []\n",
    "for i in range(look_back+look_ahead, split_index-look_ahead):\n",
    "    X_train.append(data_scaled[i-look_ahead-look_back:i-look_ahead, 0])\n",
    "    y_train.append(data_scaled[i-look_ahead:i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_val, y_val = [], []\n",
    "# Prepare validation data\n",
    "for i in range(split_index-look_ahead+1, split_val_index-look_ahead):\n",
    "    X_val.append(data_scaled[i - look_ahead - look_back:i - look_ahead, 0])\n",
    "    y_val.append(data_scaled[i - look_ahead:i, 0])\n",
    "X_val, y_val =  np.array(X_val), np.array(y_val)\n",
    "\n",
    "# Predict on the remaining data\n",
    "X_test, y_test = [], []\n",
    "for i in range(split_val_index-look_ahead+1, len(data_scaled)-look_ahead):\n",
    "    X_test.append(data_scaled[i-look_ahead-look_back:i-look_ahead, 0])\n",
    "    y_test.append(data_scaled[i-look_ahead:i, 0])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_val = len(X_val)\n",
    "n_test = len(X_test)\n",
    "n_data = len(data)\n",
    "\n",
    "print(f'Size training data: {n_train}, Size validation set: {n_val}, Size testing data: {n_test}, Size data: {n_data}')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=100)\n",
    "plt.plot(np.arange(look_back,look_back+look_ahead), y_train[0])\n",
    "plt.plot(np.arange(0, look_back), X_train[0])\n",
    "plt.plot(np.arange(split_index, split_index+look_back), X_val[0])\n",
    "plt.plot(np.arange(split_index+look_back, split_index+look_back+look_ahead), y_val[0])\n",
    "plt.plot(np.arange(split_val_index, split_val_index+look_back), X_test[0])\n",
    "plt.plot(np.arange(split_val_index+look_back, split_val_index+look_back+look_ahead), y_test[0])\n",
    "plt.legend([\"Training set, y\", \"Training set, X\", \"Validation set, X\", \"Validation set, y\",\"Testing set, X\", \"Testing set, y\"])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.ylabel(\"Consumption (kW)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = sc.fit_transform(data['Load'].values.reshape(-1,1))\n",
    "look_back =  # Number of previous time steps to use as input features\n",
    "look_ahead = \n",
    "\n",
    "training_rate = \n",
    "split_index = int((len(data))*training_rate)\n",
    "validation_rate = \n",
    "split_val_index = int((training_rate+validation_rate)*(len(data)))\n",
    "testing_rate = \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "X_train, y_train = [], []\n",
    "for i in range(look_back+look_ahead, split_index):\n",
    "    X_train.append(data_scaled[i-look_ahead-look_back:i-look_ahead, 0])\n",
    "    y_train.append(data_scaled[i-look_ahead:i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_val, y_val = [], []\n",
    "# Prepare validation data\n",
    "for i in range(split_index+look_ahead, split_val_index):\n",
    "    X_val.append(data_scaled[i - look_ahead - look_back:i - look_ahead, 0])\n",
    "    y_val.append(data_scaled[i - look_ahead:i, 0])\n",
    "X_val, y_val =  np.array(X_val), np.array(y_val)\n",
    "\n",
    "# Predict on the remaining data\n",
    "X_test, y_test = [], []\n",
    "for i in range(split_val_index+look_ahead, len(data_scaled)):\n",
    "    X_test.append(data_scaled[i-look_ahead-look_back:i-look_ahead, 0])\n",
    "    y_test.append(data_scaled[i-look_ahead:i, 0])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_val = len(X_val)\n",
    "n_test = len(X_test)\n",
    "n_data = len(data)\n",
    "\n",
    "print(f'Size training data: {n_train}, Size validation set: {n_val}, Size testing data: {n_test}, Size data: {n_data}')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=100)\n",
    "plt.plot(np.arange(look_back,look_back+look_ahead), y_train[0])\n",
    "plt.plot(np.arange(0, look_back), X_train[0])\n",
    "plt.plot(np.arange(split_index, split_index+look_back), X_val[0])\n",
    "plt.plot(np.arange(split_index+look_back, split_index+look_back+look_ahead), y_val[0])\n",
    "plt.plot(np.arange(split_val_index, split_val_index+look_back), X_test[0])\n",
    "plt.plot(np.arange(split_val_index+look_back, split_val_index+look_back+look_ahead), y_test[0])\n",
    "plt.legend([\"Training set, y\", \"Training set, X\", \"Validation set, X\", \"Validation set, y\",\"Testing set, X\", \"Testing set, y\"])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.ylabel(\"Consumption (kW)\")\n",
    "plt.xlabel('Hour')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.01186806820891568\n",
      "Mean Absolute Error (MAE): 0.05465132788918211\n",
      "Root Mean Squared Error (RMSE): 0.10894066370697253\n",
      "R-squared (R2) Score: 0.17036669793231274\n"
     ]
    }
   ],
   "source": [
    "## Metrics to evaluate the performance of your model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.models import load_model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R2) Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, TimeDistributed\n",
    "\n",
    "\n",
    "# Reshape input data for LSTM [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# # model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=look_ahead))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the PV consumption, implement your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_s =\n",
    "t_e = \n",
    "\n",
    "data = df_merged.loc[(df_merged['HourUTC']>=t_s) & (df_merged['HourUTC']<=t_e)]\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=100)\n",
    "plt.plot(data['PV'])\n",
    "plt.title('PV Production')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('PV Production (kW)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train here your own model. Plot the predicted production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "data_corr = data.drop(['HourUTC', 'Load'], axis=1)\n",
    "correlation_matrix = data_corr.corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(correlation_matrix['PV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add exogenous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "exog = ['PV', .., ... ] # Fill in the columns that you want to train the model on\n",
    "target = []\n",
    "data_scaled = sc.fit_transform(data[exog])\n",
    "target_scaled = sc.fit_transform(data[target])\n",
    "look_back =  # Number of previous time steps to use as input features\n",
    "look_ahead = \n",
    "\n",
    "training_rate = \n",
    "split_index = int((len(data)-look_back-look_ahead)*training_rate)\n",
    "validation_rate = \n",
    "split_val_index = int((training_rate+validation_rate)*(len(data)-look_ahead-look_back))\n",
    "testing_rate = \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# Prepare training data\n",
    "X_train, y_train = [], []\n",
    "for i in range(look_back+look_ahead, split_index):\n",
    "    X_train.append(data_scaled[i-look_ahead-look_back:i-look_ahead, :])\n",
    "    y_train.append(data_scaled[i-look_ahead:i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_val, y_val = [], []\n",
    "# Prepare validation data\n",
    "for i in range(split_index+look_ahead, split_val_index):\n",
    "    X_val.append(data_scaled[i - look_ahead - look_back:i - look_ahead, :])\n",
    "    y_val.append(data_scaled[i - look_ahead:i, 0])\n",
    "X_val, y_val =  np.array(X_val), np.array(y_val)\n",
    "\n",
    "# Predict on the remaining data\n",
    "X_test, y_test = [], []\n",
    "for i in range(split_val_index+look_ahead, len(data)+look_ahead):\n",
    "    X_test.append(data_scaled[i-look_ahead-look_back:i-look_ahead, :])\n",
    "    y_test.append(data_scaled[i-look_ahead:i, 0])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "n_train = len(y_train)\n",
    "n_val = len(y_val)\n",
    "n_test = len(y_test)\n",
    "n_data = len(data)\n",
    "\n",
    "print(f'Size training data: {n_train}, Size validation set: {n_val}, Size testing data: {n_test}, Size data: {n_data}')\n",
    "\n",
    "\n",
    "# Reshape input data for LSTM [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],len(exog)))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], len(exog)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train here your own model. Use metrics to evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_production = sc.inverse_transform(y_pred)\n",
    "plt.plot(np.arange(n_train+n_val+look_back+look_ahead, n_data-look_ahead), predicted_consumption, label='Predicted production')\n",
    "plt.plot(data['PV'][n_train+n_val+look_ahead+look_back:n_data-look_ahead], label='Actual production')\n",
    "plt.plot(data['PV'][:n_train+n_val+look_ahead+look_back], label = 'Historical production')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Production (kW)')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
